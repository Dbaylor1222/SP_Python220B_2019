Reviewing poor_perf functions:


analyze - Lacks docstring. Gets current time, opens csv file, calls list on each row, checks the fifth element in each list and adds date and ID to new_ones if date is after 00/00/12. After new_ones is populated, each row is checked against years 2013 through 2018, and year count dict gets updated for each match. An error exists in the last year check. year_count is printed. 

The csv file is closed and then opened again, each row is convered to a list, and then counted if 'ao' is found. Returns start, end, year_count, found.

main - assigns the filename and calls analyze.

Using timeit module, the unchanged "poor" performance was 5.4085441. Used cProfile:

1038283 function calls in 5.503 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    5.005    5.005    5.399    5.399 poor_perf.py:9(analyze)
    19100    0.286    0.000    0.286    0.000 {built-in method _codecs.char
        1    0.104    0.104    5.503    5.503 poor_perf.py:59(main)
  1000000    0.098    0.000    0.098    0.000 {method 'append' of 'list' ob
    19100    0.009    0.000    0.295    0.000 cp1252.py:22(decode)
        4    0.001    0.000    0.001    0.000 {method 'write' of '_io.TextI
        4    0.000    0.000    0.000    0.000 {method 'flush' of '_io.TextI
        2    0.000    0.000    0.000    0.000 {built-in method io.open}
        4    0.000    0.000    0.000    0.000 ansitowin32.py:245(convert_os
        2    0.000    0.000    0.001    0.001 {built-in method builtins.pri
        1    0.000    0.000    5.503    5.503 {built-in method builtins.exe
        4    0.000    0.000    0.001    0.000 ansitowin32.py:177(write_and_
        4    0.000    0.000    0.001    0.000 ansitowin32.py:193(write_plai
        8    0.000    0.000    0.000    0.000 {method 'finditer' of '_sre.S
        2    0.000    0.000    0.000    0.000 {built-in method _locale._get
        2    0.000    0.000    0.000    0.000 {built-in method now}
        2    0.000    0.000    0.000    0.000 {built-in method _csv.reader}
        4    0.000    0.000    0.001    0.000 ansitowin32.py:160(write)
        4    0.000    0.000    0.001    0.000 ansitowin32.py:40(write)
        2    0.000    0.000    0.000    0.000 _bootlocale.py:11(getpreferre
       24    0.000    0.000    0.000    0.000 future.py:47(__del__)
        1    0.000    0.000    5.503    5.503 <string>:1(<module>)
        2    0.000    0.000    0.000    0.000 codecs.py:259(__init__)
        4    0.000    0.000    0.000    0.000 {built-in method builtins.len
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof 

The bottleneck is hidden in analyze(). Rather than add in additional functions, that would show up in cProfile, I added print statements after list creation and iterations, showing a couple of seconds appending 'new_ones' and a couple of seconds re-iterating for the 'ao' count. Itried the following for performance gains:

Remove redundant file opening, moving ao count to first iteration - total: 3.1493376, change: -2.259

Remove list conversion on row - total: 3.0720449, change:-0.0772927

Count directly to year_count dict - total: 2.0489489 change: -1.023096

Tried using a separate function to count years and 'oa's and map that to the reader, but that was marginally slower at 2.2350673



