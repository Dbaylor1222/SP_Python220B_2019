First run with 0 initial records. 
$ python linear.py
Linear Result
Customers
(100000, 0, 100000, 39.9572868347168)
Products
(100000, 0, 100000, 38.33679270744324)
Rentals
(100000, 0, 100000, 44.01639986038208)
Total time elapsed 122.3114767074585 seconds

$ python parallel.py
Parallel Result
Customers
(100000, 0, 100000, 83.9998300075531)
Products
(100000, 0, 100000, 86.38743805885315)
Rentals
(100000, 0, 100000, 93.73151659965515)
Total time elapsed 93.73347783088684 seconds


Second Run with intial records in the database. 

$ python linear.py
Linear Result
Customers
(100000, 100000, 200000, 40.132620334625244)
Products
(100000, 100000, 200000, 36.52957224845886)
Rentals
(100000, 100000, 200000, 40.61763644218445)
Total time elapsed 117.27982902526855 seconds

$ python parallel.py
Parallel Result
Customers
(100000, 100000, 200000, 82.62488508224487)
Products
(100000, 100000, 200000, 85.77446031570435)
Rentals
(100000, 100000, 200000, 91.89700293540955)
Total time elapsed 91.89897012710571 seconds


Analysis:

In the first run with 0 initial records, the parallel program is ~23% faster than the linear program. 

In the second run with 100000 initial records, the parallel program is ~21% faster than the linear program. 

Note: 

The timing of running the individual module in the parallel execution is almost double than the timing of running the individual module in the linear execution.  
The parallel program uses multi-threading and each thread runs on the same python interpreter and utilizes the same memory space increasing the execution 
time. But the overall time is reduced significantly. 

Recommendation:

Since we don't share the data among the threads, it is worthwhile to implement the parallel execution to enhance the performance without a serious concern
of deadlocks. 


